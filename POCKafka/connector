connect:
    image: confluentinc/cp-kafka-connect:3.0.1
    ports:
      - "8083:8083"
    links:
      - "kafka:kafka"
      - "zookeeper:zookeeper"
    environment:
      CONNECT_BOOTSTRAP_SERVERS: kafka:9092
      CONNECT_GROUP_ID: s3-sink-test
      CONNECT_CONFIG_STORAGE_TOPIC: __slack.sink.config.storage
      CONNECT_STATUS_STORAGE_TOPIC: __slack.sink.status.storage
      CONNECT_OFFSET_STORAGE_TOPIC: __slack.sink.offset.storage
      CONNECT_VALUE_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      CONNECT_KEY_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      CONNECT_INTERNAL_KEY_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      CONNECT_INTERNAL_VALUE_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      CONNECT_REST_PORT: 8083
      CONNECT_REST_ADVERTISED_HOST_NAME: docker
      CONNECT_SCHEMAS_ENABLE: "false"
      CONNECT_VALUE_CONVERTER_SCHEMAS_ENABLE: "false"
      CONNECT_KEY_CONVERTER_SCHEMAS_ENABLE: "false"
      CONNECT_ZOOKEEPER_CONNECT: zookeeper:2181

    command:
          - bash
          - -c
          - |
            echo "Installing Connector"
            confluent-hub install --no-prompt confluentinc/kafka-connect-s3:10.0.2
            #
            echo "Launching Kafka Connect worker"
            /etc/confluent/docker/run &
            #
            sleep infinity


  { "name": "kafka-to-s3", "config": { "connector.class":"io.confluent.connect.s3.S3SinkConnector", "tasks.max":"1", "topics":"teste-s3", "s3.bucket.name":"test.raw.datalake.kovi.us", "s3.region":"us-west-1", "s3.part.size":"5242880", "flush.size":"100000", "key.converter":"org.apache.kafka.connect.json.JsonConverter", "key.converter.schemas.enable":"false", "value.converter":"org.apache.kafka.connect.json.JsonConverter",\ "value.converter.schemas.enable":"false", "storage.class":"io.confluent.connect.s3.storage.S3Storage", "format.class":"io.confluent.connect.s3.format.parquet.ParquetFormat", "schema.compatibility":"NONE", "partitioner.class":"io.confluent.connect.storage.partitioner.TimeBasedPartitioner", "locale":"en", "timezone":"UTC", "path.format":"'date'=YYYY-MM-dd/'hour'=HH", "partition.duration.ms":"3600000", "rotate.interval.ms":"60000", "timestamp.extractor":"Record" "aws.access.key.id":"AKIA3E2BNHKXPOHRCSXV" "aws.secret.access.key":"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" } }


curl -X POST localhost:8083/connectors/kafka-to-s3/restart


curl -X POST ec2-3-95-64-58.compute-1.amazonaws.com:8083/connectors -H 'Content-Type: application/json' -d '{ "name": "kafka-to-s3", "config": { "connector.class":"io.confluent.connect.s3.S3SinkConnector", "tasks.max":"1", "topics":"teste-s3", "s3.bucket.name":"test.raw.datalake.kovi.us", "s3.region":"us-west-1", "s3.part.size":"5242880", "flush.size":"100000", "key.converter":"org.apache.kafka.connect.json.JsonConverter", "key.converter.schemas.enable":"false", "value.converter":"org.apache.kafka.connect.json.JsonConverter", "value.converter.schemas.enable":"false", "storage.class":"io.confluent.connect.s3.storage.S3Storage", "format.class":"io.confluent.connect.s3.format.parquet.ParquetFormat", "schema.compatibility":"NONE", "partitioner.class":"io.confluent.connect.storage.partitioner.TimeBasedPartitioner", "locale":"en", "timezone":"UTC", "path.format":"'date'=YYYY-MM-dd/'hour'=HH", "partition.duration.ms":"3600000", "rotate.interval.ms":"60000", "timestamp.extractor":"Record", "aws.access.key.id":"AKIA3E2BNHKXPOHRCSXV", "aws.secret.access.key":"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" } }'